# üìä Documentaci√≥n del Proyecto de Detecci√≥n de Intrusiones con Random Forest

## üìã √çndice
1. [Descripci√≥n General](#descripci√≥n-general)
2. [Preparaci√≥n de Datos](#preparaci√≥n-de-datos)
3. [Proceso de Entrenamiento](#proceso-de-entrenamiento)
4. [Datos de Entrada](#datos-de-entrada)
5. [Datos de Salida](#datos-de-salida)
6. [Visualizaciones Generadas](#visualizaciones-generadas)
7. [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)

---

## üéØ Descripci√≥n General

Este proyecto implementa un sistema de detecci√≥n de intrusiones de red utilizando **Random Forest** sobre el dataset **KDD Cup 1999**. El objetivo es clasificar el tr√°fico de red en dos categor√≠as:
- **Normal (0)**: Tr√°fico leg√≠timo
- **Attack (1)**: Tr√°fico malicioso o intrusi√≥n

---

## üì• Preparaci√≥n de Datos

### Script: `download_and_chunk.py`

Este script descarga y procesa el dataset KDD Cup 1999.

#### **Proceso de Transformaci√≥n:**

1. **Carga del Dataset**: Lee el archivo `DDTrain.txt` o `KDDTrain.txt` con 42 columnas originales
2. **Creaci√≥n de Variable Objetivo**: 
   - Columna `binario`: 0 si `class == "normal"`, 1 en caso contrario
3. **Codificaci√≥n de Variables Categ√≥ricas**:
   - `protocol_type`: Tipo de protocolo (tcp, udp, icmp)
   - `service`: Servicio de red (http, ftp, smtp, etc.)
   - `flag`: Estado de la conexi√≥n (SF, REJ, S0, etc.)
   - Se aplica **One-Hot Encoding** con `pd.get_dummies()`
4. **Eliminaci√≥n de Columnas**: Se elimina la columna `class` original
5. **Salida**: Archivo `KDD_TRAIN_FULL.csv` con todas las caracter√≠sticas num√©ricas

#### **Caracter√≠sticas del Dataset Procesado:**
- **Total de registros**: ~125,973 muestras
- **Caracter√≠sticas**: ~120 columnas (despu√©s de one-hot encoding)
- **Distribuci√≥n de clases**:
  - Normal: 67,343 muestras (53.5%)
  - Attack: 58,630 muestras (46.5%)

---

## üß† Proceso de Entrenamiento

### Script: `train_random_forest.py`

#### **Paso 1: Carga de Datos**
```python
df = pd.read_csv(CSV_PATH)
X = df.drop(columns=["binario"])  # Caracter√≠sticas
y = df["binario"]                  # Variable objetivo
```

#### **Paso 2: Divisi√≥n de Datos**
- **Train**: 80% de los datos (100,778 muestras)
- **Test**: 20% de los datos (25,195 muestras)
- **Estratificaci√≥n**: Se mantiene la proporci√≥n de clases en ambos conjuntos
- **Semilla aleatoria**: `random_state=42` (reproducibilidad)

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)
```

#### **Paso 3: Configuraci√≥n del Modelo**
- **Algoritmo**: Random Forest Classifier
- **Manejo de desbalance**: `class_weight="balanced"`
- **Paralelizaci√≥n**: `n_jobs=2` (para evitar problemas de memoria)

#### **Paso 4: Optimizaci√≥n de Hiperpar√°metros**
Se utiliza **RandomizedSearchCV** para encontrar los mejores hiperpar√°metros:

| Hiperpar√°metro | Rango de B√∫squeda | Mejor Valor |
|----------------|-------------------|-------------|
| `n_estimators` | 50 - 150 | 121 |
| `max_depth` | 10 - 30 | 16 |
| `min_samples_split` | 2 - 8 | 4 |
| `min_samples_leaf` | 1 - 5 | 1 |
| `max_features` | sqrt, log2 | log2 |

**Configuraci√≥n de validaci√≥n cruzada:**
- **M√©todo**: StratifiedKFold
- **N√∫mero de folds**: 3
- **M√©trica de optimizaci√≥n**: F1-Score
- **Iteraciones**: 5 b√∫squedas aleatorias

#### **Paso 5: Entrenamiento Final**
El modelo con los mejores hiperpar√°metros se entrena con todo el conjunto de entrenamiento.

#### **Paso 6: Evaluaci√≥n**
Se eval√∫a el modelo en el conjunto de prueba calculando:
- Accuracy
- ROC-AUC
- Classification Report (Precision, Recall, F1-Score)
- Confusion Matrix

---

## üìä Datos de Entrada

### Archivo: `scripts/KDD_TRAIN_FULL.csv`

**Caracter√≠sticas principales del dataset:**

#### **1. Caracter√≠sticas B√°sicas de Conexi√≥n** (9 columnas)
- `duration`: Duraci√≥n de la conexi√≥n en segundos
- `src_bytes`: Bytes enviados desde el origen
- `dst_bytes`: Bytes enviados al destino
- `land`: 1 si origen y destino son iguales
- `wrong_fragment`: N√∫mero de fragmentos incorrectos
- `urgent`: N√∫mero de paquetes urgentes
- `hot`: N√∫mero de indicadores "hot"
- `num_failed_logins`: N√∫mero de intentos de login fallidos
- `logged_in`: 1 si el login fue exitoso

#### **2. Caracter√≠sticas de Contenido** (13 columnas)
- `num_compromised`: N√∫mero de condiciones comprometidas
- `root_shell`: 1 si se obtuvo acceso root
- `su_attempted`: 1 si se intent√≥ comando "su"
- `num_root`: N√∫mero de accesos root
- `num_file_creations`: N√∫mero de operaciones de creaci√≥n de archivos
- `num_shells`: N√∫mero de shells abiertos
- `num_access_files`: N√∫mero de operaciones en archivos de control de acceso
- Y m√°s...

#### **3. Caracter√≠sticas de Tr√°fico** (9 columnas)
- `count`: N√∫mero de conexiones al mismo host
- `srv_count`: N√∫mero de conexiones al mismo servicio
- `serror_rate`: Tasa de errores SYN
- `srv_serror_rate`: Tasa de errores SYN para el servicio
- `rerror_rate`: Tasa de errores REJ
- `srv_rerror_rate`: Tasa de errores REJ para el servicio
- `same_srv_rate`: Tasa de conexiones al mismo servicio
- `diff_srv_rate`: Tasa de conexiones a diferentes servicios
- `srv_diff_host_rate`: Tasa de conexiones del servicio a diferentes hosts

#### **4. Caracter√≠sticas del Host** (10 columnas)
- `dst_host_count`: N√∫mero de conexiones al host destino
- `dst_host_srv_count`: N√∫mero de conexiones al servicio del host destino
- `dst_host_same_srv_rate`: Tasa de conexiones al mismo servicio del host
- `dst_host_diff_srv_rate`: Tasa de conexiones a diferentes servicios del host
- Y m√°s estad√≠sticas del host destino...

#### **5. Variables Categ√≥ricas (One-Hot Encoded)**
- **protocol_type**: tcp, udp, icmp (~3 columnas)
- **service**: http, ftp, smtp, telnet, etc. (~70 columnas)
- **flag**: SF, S0, REJ, RSTR, etc. (~11 columnas)

#### **6. Variable Objetivo**
- `binario`: 0 (Normal) o 1 (Attack)

**Total de caracter√≠sticas**: ~120 columnas num√©ricas

---

## üì§ Datos de Salida

### 1. Modelo Entrenado
**Archivo**: `output/rf_kdd_model.joblib`
- **Tama√±o**: ~6.4 MB
- **Formato**: Serializado con joblib
- **Contenido**: Modelo Random Forest completo con 121 √°rboles de decisi√≥n

### 2. M√©tricas de Rendimiento
**Archivo**: `output/rf_kdd_metrics.txt`

```
Best params:
{'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 1, 
 'min_samples_split': 4, 'n_estimators': 121}

Accuracy: 0.9987299067275253
ROC AUC: 0.9999956121881989

Classification report:
              precision    recall  f1-score   support

           0     0.9987    0.9989    0.9988     13469
           1     0.9987    0.9986    0.9986     11726

    accuracy                         0.9987     25195
   macro avg     0.9987    0.9987    0.9987     25195
weighted avg     0.9987    0.9987    0.9987     25195

Confusion matrix:
[[13454    15]
 [   17 11709]]
```

**Interpretaci√≥n de m√©tricas:**
- **Accuracy (99.87%)**: El modelo clasifica correctamente el 99.87% de las muestras
- **ROC-AUC (0.99999)**: Excelente capacidad de discriminaci√≥n entre clases
- **Precision (99.87%)**: De las predicciones positivas, 99.87% son correctas
- **Recall (99.86%)**: El modelo detecta el 99.86% de los ataques reales
- **F1-Score (99.86%)**: Balance √≥ptimo entre precision y recall

**Matriz de Confusi√≥n:**
- **Verdaderos Negativos (TN)**: 13,454 - Tr√°fico normal correctamente identificado
- **Falsos Positivos (FP)**: 15 - Tr√°fico normal clasificado como ataque
- **Falsos Negativos (FN)**: 17 - Ataques no detectados
- **Verdaderos Positivos (TP)**: 11,709 - Ataques correctamente detectados

---

## üìà Visualizaciones Generadas

### Script: `generate_visualizations.py`

Este script genera 6 visualizaciones en formato HTML (interactivo) y PNG (est√°tico).

---

### 1Ô∏è‚É£ **Matriz de Confusi√≥n** (`confusion_matrix.png/html`)

![Confusion Matrix](output/plots/confusion_matrix.png)

#### **Descripci√≥n:**
Muestra la relaci√≥n entre las predicciones del modelo y los valores reales.

#### **Interpretaci√≥n:**
- **Eje X**: Predicciones del modelo (Normal vs Attack)
- **Eje Y**: Valores reales (Normal vs Attack)
- **Colores**: Azul m√°s oscuro indica mayor cantidad de muestras
- **N√∫meros**: Cantidad absoluta y porcentaje de cada celda

#### **Qu√© nos dice:**
- **Diagonal principal** (azul oscuro): Alta concentraci√≥n = modelo preciso
- **Fuera de diagonal** (azul claro): Pocos errores
- **Celda superior derecha (FP=15)**: Solo 15 falsos positivos (0.1%)
- **Celda inferior izquierda (FN=17)**: Solo 17 falsos negativos (0.1%)

**Conclusi√≥n**: El modelo tiene un rendimiento excepcional con muy pocos errores.

---

### 2Ô∏è‚É£ **Curva ROC** (`roc_curve.png/html`)

![ROC Curve](output/plots/roc_curve.png)

#### **Descripci√≥n:**
Representa la capacidad del modelo para discriminar entre clases a diferentes umbrales de decisi√≥n.

#### **Interpretaci√≥n:**
- **Eje X**: Tasa de Falsos Positivos (FPR) - Proporci√≥n de normales clasificados como ataques
- **Eje Y**: Tasa de Verdaderos Positivos (TPR) - Proporci√≥n de ataques detectados
- **L√≠nea naranja**: Curva ROC del modelo
- **L√≠nea azul punteada**: Clasificador aleatorio (AUC = 0.5)
- **AUC (Area Under Curve)**: 0.9999956 ‚âà 1.0

#### **Qu√© nos dice:**
- **Curva pegada a la esquina superior izquierda**: Modelo casi perfecto
- **AUC ‚âà 1.0**: Discriminaci√≥n perfecta entre clases
- **Distancia de la diagonal**: Cuanto m√°s alejada, mejor el modelo

**Conclusi√≥n**: El modelo puede distinguir perfectamente entre tr√°fico normal y ataques.

---

### 3Ô∏è‚É£ **Curva Precision-Recall** (`precision_recall.png/html`)

![Precision-Recall Curve](output/plots/precision_recall.png)

#### **Descripci√≥n:**
Muestra el balance entre precisi√≥n y recall a diferentes umbrales, especialmente √∫til para datasets desbalanceados.

#### **Interpretaci√≥n:**
- **Eje X**: Recall (Sensibilidad) - Proporci√≥n de ataques detectados
- **Eje Y**: Precision - Proporci√≥n de predicciones correctas
- **L√≠nea verde**: Curva PR del modelo
- **AUC**: 0.9999 (√°rea bajo la curva)

#### **Qu√© nos dice:**
- **Curva cerca de la esquina superior derecha**: Excelente balance
- **Alta precisi√≥n y alto recall simult√°neamente**: Modelo robusto
- **AUC ‚âà 1.0**: Rendimiento √≥ptimo en ambas m√©tricas

**Conclusi√≥n**: El modelo mantiene alta precisi√≥n incluso con alto recall, ideal para detecci√≥n de intrusiones.

---

### 4Ô∏è‚É£ **Importancia de Caracter√≠sticas** (`feature_importance.png/html`)

![Feature Importance](output/plots/feature_importance.png)

#### **Descripci√≥n:**
Muestra las 15 caracter√≠sticas m√°s importantes para las decisiones del modelo.

#### **Interpretaci√≥n:**
- **Eje X**: Importancia (contribuci√≥n a la predicci√≥n)
- **Eje Y**: Nombre de la caracter√≠stica
- **Barras m√°s largas**: Caracter√≠sticas m√°s influyentes

#### **Caracter√≠sticas principales t√≠picas:**
1. **src_bytes**: Bytes enviados desde el origen
2. **dst_bytes**: Bytes enviados al destino
3. **count**: N√∫mero de conexiones al mismo host
4. **srv_count**: N√∫mero de conexiones al mismo servicio
5. **dst_host_srv_count**: Conexiones al servicio del host destino
6. **Flags espec√≠ficos**: Estados de conexi√≥n (SF, S0, etc.)
7. **Services espec√≠ficos**: Servicios de red (http, ftp, etc.)

#### **Qu√© nos dice:**
- **Caracter√≠sticas de tr√°fico dominan**: Patrones de conexi√≥n son clave
- **Variables num√©ricas vs categ√≥ricas**: Ambas son importantes
- **Caracter√≠sticas de host**: Comportamiento agregado es relevante

**Conclusi√≥n**: El modelo se basa principalmente en patrones de tr√°fico y caracter√≠sticas de conexi√≥n para detectar intrusiones.

---

### 5Ô∏è‚É£ **Distribuci√≥n de Clases** (`class_distribution.png/html`)

![Class Distribution](output/plots/class_distribution.png)

#### **Descripci√≥n:**
Muestra la cantidad de muestras de cada clase en el dataset completo.

#### **Interpretaci√≥n:**
- **Barra azul (Normal)**: ~67,343 muestras (53.5%)
- **Barra coral (Attack)**: ~58,630 muestras (46.5%)
- **N√∫meros sobre barras**: Cantidad exacta de muestras

#### **Qu√© nos dice:**
- **Dataset relativamente balanceado**: Proporci√≥n 53/47
- **No hay desbalance severo**: No se requieren t√©cnicas agresivas de balanceo
- **Suficientes muestras de ambas clases**: Entrenamiento robusto

**Conclusi√≥n**: El dataset tiene una distribuci√≥n equilibrada, lo que facilita el entrenamiento y evita sesgos hacia una clase.

---

### 6Ô∏è‚É£ **Resumen de Rendimiento** (`performance_summary.png/html`)

![Performance Summary](output/plots/performance_summary.png)

#### **Descripci√≥n:**
Comparaci√≥n visual de las principales m√©tricas de evaluaci√≥n del modelo.

#### **Interpretaci√≥n:**
Las 5 m√©tricas clave mostradas son:

1. **Accuracy (0.9987)**: Proporci√≥n total de predicciones correctas
   - **Qu√© mide**: Rendimiento general del modelo
   - **Valor √≥ptimo**: 1.0 (100%)
   
2. **Precision (0.9987)**: Proporci√≥n de predicciones positivas correctas
   - **Qu√© mide**: Confiabilidad de las alertas de ataque
   - **Valor √≥ptimo**: 1.0 (sin falsos positivos)
   
3. **Recall (0.9986)**: Proporci√≥n de ataques reales detectados
   - **Qu√© mide**: Capacidad de detectar todos los ataques
   - **Valor √≥ptimo**: 1.0 (sin falsos negativos)
   
4. **F1-Score (0.9986)**: Media arm√≥nica de precision y recall
   - **Qu√© mide**: Balance entre precision y recall
   - **Valor √≥ptimo**: 1.0 (balance perfecto)
   
5. **ROC-AUC (0.9999)**: √Årea bajo la curva ROC
   - **Qu√© mide**: Capacidad de discriminaci√≥n entre clases
   - **Valor √≥ptimo**: 1.0 (separaci√≥n perfecta)

#### **Qu√© nos dice:**
- **Todas las m√©tricas > 0.998**: Rendimiento excepcional
- **M√©tricas equilibradas**: No hay trade-offs significativos
- **ROC-AUC casi perfecto**: Excelente capacidad de clasificaci√≥n

**Conclusi√≥n**: El modelo tiene un rendimiento sobresaliente en todas las m√©tricas, siendo apto para producci√≥n.

---

## üéØ Interpretaci√≥n de Resultados

### **Rendimiento del Modelo**

El Random Forest entrenado muestra un rendimiento **excepcional**:

‚úÖ **Fortalezas:**
- **Accuracy del 99.87%**: Clasifica correctamente casi todas las muestras
- **ROC-AUC de 0.9999**: Discriminaci√≥n casi perfecta entre clases
- **Muy pocos errores**: Solo 32 errores en 25,195 muestras de prueba
- **Balance perfecto**: Precision y Recall casi id√©nticos (no hay trade-off)
- **Generalizaci√≥n**: Validaci√≥n cruzada confirma estabilidad

‚ö†Ô∏è **Consideraciones:**
- **Posible overfitting**: Rendimiento muy alto puede indicar sobreajuste
- **Dataset sint√©tico**: KDD Cup 1999 es un dataset antiguo y sint√©tico
- **Validaci√≥n en producci√≥n**: Probar con tr√°fico de red real
- **Actualizaci√≥n continua**: Los patrones de ataque evolucionan

### **Aplicaciones Pr√°cticas**

Este modelo puede ser utilizado para:
1. **Sistemas IDS/IPS**: Detecci√≥n en tiempo real de intrusiones
2. **An√°lisis forense**: Identificaci√≥n de patrones de ataque hist√≥ricos
3. **Monitoreo de red**: Alertas autom√°ticas de tr√°fico sospechoso
4. **Investigaci√≥n**: Baseline para comparar nuevos algoritmos

### **Pr√≥ximos Pasos Recomendados**

1. **Validaci√≥n con datos reales**: Probar con tr√°fico de red actual
2. **An√°lisis de errores**: Estudiar los 32 casos mal clasificados
3. **Optimizaci√≥n**: Reducir el tama√±o del modelo sin perder rendimiento
4. **Deployment**: Integrar en un sistema de monitoreo real
5. **Actualizaci√≥n**: Reentrenar con nuevos tipos de ataques

---

## üìÅ Estructura de Archivos

```
Prueba-dataset/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ download_and_chunk.py          # Descarga y preprocesa datos
‚îÇ   ‚îú‚îÄ‚îÄ train_random_forest.py         # Entrena el modelo
‚îÇ   ‚îú‚îÄ‚îÄ generate_visualizations.py     # Genera gr√°ficos
‚îÇ   ‚îî‚îÄ‚îÄ KDD_TRAIN_FULL.csv            # Dataset procesado
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ rf_kdd_model.joblib           # Modelo entrenado
‚îÇ   ‚îú‚îÄ‚îÄ rf_kdd_metrics.txt            # M√©tricas de evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ plots/                         # Visualizaciones
‚îÇ       ‚îú‚îÄ‚îÄ confusion_matrix.png/html
‚îÇ       ‚îú‚îÄ‚îÄ roc_curve.png/html
‚îÇ       ‚îú‚îÄ‚îÄ precision_recall.png/html
‚îÇ       ‚îú‚îÄ‚îÄ feature_importance.png/html
‚îÇ       ‚îú‚îÄ‚îÄ class_distribution.png/html
‚îÇ       ‚îî‚îÄ‚îÄ performance_summary.png/html
‚îî‚îÄ‚îÄ README_TRAINING.md                 # Esta documentaci√≥n
```

---

## üöÄ C√≥mo Ejecutar el Proyecto

### **1. Preparar los datos**
```bash
python scripts/download_and_chunk.py
```

### **2. Entrenar el modelo**
```bash
python scripts/train_random_forest.py
```

### **3. Generar visualizaciones**
```bash
python scripts/generate_visualizations.py
```

---

## üìö Referencias

- **Dataset**: KDD Cup 1999 - Network Intrusion Detection
- **Algoritmo**: Random Forest (Breiman, 2001)
- **M√©tricas**: Scikit-learn Documentation
- **Visualizaciones**: Plotly Python Library

---

**Autor**: Sistema de Detecci√≥n de Intrusiones con Machine Learning  
**Fecha**: 2025  
**Versi√≥n**: 1.0
