# ğŸ“Š DocumentaciÃ³n del Proyecto de DetecciÃ³n de Intrusiones con Random Forest

## ğŸ“‹ Ãndice
1. [DescripciÃ³n General](#descripciÃ³n-general)
2. [PreparaciÃ³n de Datos](#preparaciÃ³n-de-datos)
3. [Proceso de Entrenamiento](#proceso-de-entrenamiento)
4. [Datos de Entrada](#datos-de-entrada)
5. [Datos de Salida](#datos-de-salida)
6. [Visualizaciones Generadas](#visualizaciones-generadas)
7. [InterpretaciÃ³n de Resultados](#interpretaciÃ³n-de-resultados)

---

## ğŸ¯ DescripciÃ³n General

Este proyecto implementa un sistema de detecciÃ³n de intrusiones de red utilizando **Random Forest** sobre el dataset **KDD Cup 1999**. El objetivo es clasificar el trÃ¡fico de red en dos categorÃ­as:
- **Normal (0)**: TrÃ¡fico legÃ­timo
- **Attack (1)**: TrÃ¡fico malicioso o intrusiÃ³n

---

## ğŸ“¥ PreparaciÃ³n de Datos

### Script: `download_and_chunk.py`

Este script descarga y procesa el dataset KDD Cup 1999.

#### **Proceso de TransformaciÃ³n:**

1. **Carga del Dataset**: Lee el archivo `DDTrain.txt` o `KDDTrain.txt` con 42 columnas originales
2. **CreaciÃ³n de Variable Objetivo**: 
   - Columna `binario`: 0 si `class == "normal"`, 1 en caso contrario
3. **CodificaciÃ³n de Variables CategÃ³ricas**:
   - `protocol_type`: Tipo de protocolo (tcp, udp, icmp)
   - `service`: Servicio de red (http, ftp, smtp, etc.)
   - `flag`: Estado de la conexiÃ³n (SF, REJ, S0, etc.)
   - Se aplica **One-Hot Encoding** con `pd.get_dummies()`
4. **EliminaciÃ³n de Columnas**: Se elimina la columna `class` original
5. **Salida**: Archivo `KDD_TRAIN_FULL.csv` con todas las caracterÃ­sticas numÃ©ricas

#### **CaracterÃ­sticas del Dataset Procesado:**
- **Total de registros**: ~125,973 muestras
- **CaracterÃ­sticas**: ~120 columnas (despuÃ©s de one-hot encoding)
- **DistribuciÃ³n de clases**:
  - Normal: 67,343 muestras (53.5%)
  - Attack: 58,630 muestras (46.5%)

---

## ğŸ§  Proceso de Entrenamiento

### Script: `train_random_forest.py`

#### **Paso 1: Carga de Datos**
```python
df = pd.read_csv(CSV_PATH)
X = df.drop(columns=["binario"])  # CaracterÃ­sticas
y = df["binario"]                  # Variable objetivo
```

#### **Paso 2: DivisiÃ³n de Datos**
- **Train**: 80% de los datos (100,778 muestras)
- **Test**: 20% de los datos (25,195 muestras)
- **EstratificaciÃ³n**: Se mantiene la proporciÃ³n de clases en ambos conjuntos
- **Semilla aleatoria**: `random_state=42` (reproducibilidad)

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)
```

#### **Paso 3: ConfiguraciÃ³n del Modelo**
- **Algoritmo**: Random Forest Classifier
- **Manejo de desbalance**: `class_weight="balanced"`
- **ParalelizaciÃ³n**: `n_jobs=2` (para evitar problemas de memoria)

#### **Paso 4: OptimizaciÃ³n de HiperparÃ¡metros**
Se utiliza **RandomizedSearchCV** para encontrar los mejores hiperparÃ¡metros:

| HiperparÃ¡metro | Rango de BÃºsqueda | Mejor Valor |
|----------------|-------------------|-------------|
| `n_estimators` | 50 - 150 | 121 |
| `max_depth` | 10 - 30 | 16 |
| `min_samples_split` | 2 - 8 | 4 |
| `min_samples_leaf` | 1 - 5 | 1 |
| `max_features` | sqrt, log2 | log2 |

**ConfiguraciÃ³n de validaciÃ³n cruzada:**
- **MÃ©todo**: StratifiedKFold
- **NÃºmero de folds**: 3
- **MÃ©trica de optimizaciÃ³n**: F1-Score
- **Iteraciones**: 5 bÃºsquedas aleatorias

#### **Paso 5: Entrenamiento Final**
El modelo con los mejores hiperparÃ¡metros se entrena con todo el conjunto de entrenamiento.

#### **Paso 6: EvaluaciÃ³n**
Se evalÃºa el modelo en el conjunto de prueba calculando:
- Accuracy
- ROC-AUC
- Classification Report (Precision, Recall, F1-Score)
- Confusion Matrix

---

## ğŸ“Š Datos de Entrada

### Archivo: `scripts/KDD_TRAIN_FULL.csv`

**CaracterÃ­sticas principales del dataset:**

#### **1. CaracterÃ­sticas BÃ¡sicas de ConexiÃ³n** (9 columnas)
- `duration`: DuraciÃ³n de la conexiÃ³n en segundos
- `src_bytes`: Bytes enviados desde el origen
- `dst_bytes`: Bytes enviados al destino
- `land`: 1 si origen y destino son iguales
- `wrong_fragment`: NÃºmero de fragmentos incorrectos
- `urgent`: NÃºmero de paquetes urgentes
- `hot`: NÃºmero de indicadores "hot"
- `num_failed_logins`: NÃºmero de intentos de login fallidos
- `logged_in`: 1 si el login fue exitoso

#### **2. CaracterÃ­sticas de Contenido** (13 columnas)
- `num_compromised`: NÃºmero de condiciones comprometidas
- `root_shell`: 1 si se obtuvo acceso root
- `su_attempted`: 1 si se intentÃ³ comando "su"
- `num_root`: NÃºmero de accesos root
- `num_file_creations`: NÃºmero de operaciones de creaciÃ³n de archivos
- `num_shells`: NÃºmero de shells abiertos
- `num_access_files`: NÃºmero de operaciones en archivos de control de acceso
- Y mÃ¡s...

#### **3. CaracterÃ­sticas de TrÃ¡fico** (9 columnas)
- `count`: NÃºmero de conexiones al mismo host
- `srv_count`: NÃºmero de conexiones al mismo servicio
- `serror_rate`: Tasa de errores SYN
- `srv_serror_rate`: Tasa de errores SYN para el servicio
- `rerror_rate`: Tasa de errores REJ
- `srv_rerror_rate`: Tasa de errores REJ para el servicio
- `same_srv_rate`: Tasa de conexiones al mismo servicio
- `diff_srv_rate`: Tasa de conexiones a diferentes servicios
- `srv_diff_host_rate`: Tasa de conexiones del servicio a diferentes hosts

#### **4. CaracterÃ­sticas del Host** (10 columnas)
- `dst_host_count`: NÃºmero de conexiones al host destino
- `dst_host_srv_count`: NÃºmero de conexiones al servicio del host destino
- `dst_host_same_srv_rate`: Tasa de conexiones al mismo servicio del host
- `dst_host_diff_srv_rate`: Tasa de conexiones a diferentes servicios del host
- Y mÃ¡s estadÃ­sticas del host destino...

#### **5. Variables CategÃ³ricas (One-Hot Encoded)**
- **protocol_type**: tcp, udp, icmp (~3 columnas)
- **service**: http, ftp, smtp, telnet, etc. (~70 columnas)
- **flag**: SF, S0, REJ, RSTR, etc. (~11 columnas)

#### **6. Variable Objetivo**
- `binario`: 0 (Normal) o 1 (Attack)

**Total de caracterÃ­sticas**: ~120 columnas numÃ©ricas

---

## ğŸ“¤ Datos de Salida

### 1. Modelo Entrenado
**Archivo**: `output/rf_kdd_model.joblib`
- **TamaÃ±o**: ~6.4 MB
- **Formato**: Serializado con joblib
- **Contenido**: Modelo Random Forest completo con 121 Ã¡rboles de decisiÃ³n

### 2. MÃ©tricas de Rendimiento
**Archivo**: `output/rf_kdd_metrics.txt`

```
Best params:
{'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 1, 
 'min_samples_split': 4, 'n_estimators': 121}

Accuracy: 0.9987299067275253
ROC AUC: 0.9999956121881989

Classification report:
              precision    recall  f1-score   support

           0     0.9987    0.9989    0.9988     13469
           1     0.9987    0.9986    0.9986     11726

    accuracy                         0.9987     25195
   macro avg     0.9987    0.9987    0.9987     25195
weighted avg     0.9987    0.9987    0.9987     25195

Confusion matrix:
[[13454    15]
 [   17 11709]]
```

**InterpretaciÃ³n de mÃ©tricas:**
- **Accuracy (99.87%)**: El modelo clasifica correctamente el 99.87% de las muestras
- **ROC-AUC (0.99999)**: Excelente capacidad de discriminaciÃ³n entre clases
- **Precision (99.87%)**: De las predicciones positivas, 99.87% son correctas
- **Recall (99.86%)**: El modelo detecta el 99.86% de los ataques reales
- **F1-Score (99.86%)**: Balance Ã³ptimo entre precision y recall

**Matriz de ConfusiÃ³n:**
- **Verdaderos Negativos (TN)**: 13,454 - TrÃ¡fico normal correctamente identificado
- **Falsos Positivos (FP)**: 15 - TrÃ¡fico normal clasificado como ataque
- **Falsos Negativos (FN)**: 17 - Ataques no detectados
- **Verdaderos Positivos (TP)**: 11,709 - Ataques correctamente detectados

---

## ğŸ“ˆ Visualizaciones Generadas

### Script: `generate_visualizations.py`

Este script genera 6 visualizaciones en formato HTML (interactivo) y PNG (estÃ¡tico).

---

### 1ï¸âƒ£ **Matriz de ConfusiÃ³n** (`confusion_matrix.png/html`)

![Confusion Matrix](output/plots/confusion_matrix.png)

#### **DescripciÃ³n:**
Muestra la relaciÃ³n entre las predicciones del modelo y los valores reales.

#### **InterpretaciÃ³n:**
- **Eje X**: Predicciones del modelo (Normal vs Attack)
- **Eje Y**: Valores reales (Normal vs Attack)
- **Colores**: Azul mÃ¡s oscuro indica mayor cantidad de muestras
- **NÃºmeros**: Cantidad absoluta y porcentaje de cada celda

#### **QuÃ© nos dice:**
- **Diagonal principal** (azul oscuro): Alta concentraciÃ³n = modelo preciso
- **Fuera de diagonal** (azul claro): Pocos errores
- **Celda superior derecha (FP=15)**: Solo 15 falsos positivos (0.1%)
- **Celda inferior izquierda (FN=17)**: Solo 17 falsos negativos (0.1%)

**ConclusiÃ³n**: El modelo tiene un rendimiento excepcional con muy pocos errores.

---

### 2ï¸âƒ£ **Curva ROC** (`roc_curve.png/html`)

![ROC Curve](output/plots/roc_curve.png)

#### **DescripciÃ³n:**
Representa la capacidad del modelo para discriminar entre clases a diferentes umbrales de decisiÃ³n.

#### **InterpretaciÃ³n:**
- **Eje X**: Tasa de Falsos Positivos (FPR) - ProporciÃ³n de normales clasificados como ataques
- **Eje Y**: Tasa de Verdaderos Positivos (TPR) - ProporciÃ³n de ataques detectados
- **LÃ­nea naranja**: Curva ROC del modelo
- **LÃ­nea azul punteada**: Clasificador aleatorio (AUC = 0.5)
- **AUC (Area Under Curve)**: 0.9999956 â‰ˆ 1.0

#### **QuÃ© nos dice:**
- **Curva pegada a la esquina superior izquierda**: Modelo casi perfecto
- **AUC â‰ˆ 1.0**: DiscriminaciÃ³n perfecta entre clases
- **Distancia de la diagonal**: Cuanto mÃ¡s alejada, mejor el modelo

**ConclusiÃ³n**: El modelo puede distinguir perfectamente entre trÃ¡fico normal y ataques.

---

### 3ï¸âƒ£ **Curva Precision-Recall** (`precision_recall.png/html`)

![Precision-Recall Curve](output/plots/precision_recall.png)

#### **DescripciÃ³n:**
Muestra el balance entre precisiÃ³n y recall a diferentes umbrales, especialmente Ãºtil para datasets desbalanceados.

#### **InterpretaciÃ³n:**
- **Eje X**: Recall (Sensibilidad) - ProporciÃ³n de ataques detectados
- **Eje Y**: Precision - ProporciÃ³n de predicciones correctas
- **LÃ­nea verde**: Curva PR del modelo
- **AUC**: 0.9999 (Ã¡rea bajo la curva)

#### **QuÃ© nos dice:**
- **Curva cerca de la esquina superior derecha**: Excelente balance
- **Alta precisiÃ³n y alto recall simultÃ¡neamente**: Modelo robusto
- **AUC â‰ˆ 1.0**: Rendimiento Ã³ptimo en ambas mÃ©tricas

**ConclusiÃ³n**: El modelo mantiene alta precisiÃ³n incluso con alto recall, ideal para detecciÃ³n de intrusiones.

---

### 4ï¸âƒ£ **Importancia de CaracterÃ­sticas** (`feature_importance.png/html`)

![Feature Importance](output/plots/feature_importance.png)

#### **DescripciÃ³n:**
Muestra las 15 caracterÃ­sticas mÃ¡s importantes para las decisiones del modelo.

#### **InterpretaciÃ³n:**
- **Eje X**: Importancia (contribuciÃ³n a la predicciÃ³n)
- **Eje Y**: Nombre de la caracterÃ­stica
- **Barras mÃ¡s largas**: CaracterÃ­sticas mÃ¡s influyentes

#### **CaracterÃ­sticas principales tÃ­picas:**
1. **src_bytes**: Bytes enviados desde el origen
2. **dst_bytes**: Bytes enviados al destino
3. **count**: NÃºmero de conexiones al mismo host
4. **srv_count**: NÃºmero de conexiones al mismo servicio
5. **dst_host_srv_count**: Conexiones al servicio del host destino
6. **Flags especÃ­ficos**: Estados de conexiÃ³n (SF, S0, etc.)
7. **Services especÃ­ficos**: Servicios de red (http, ftp, etc.)

#### **QuÃ© nos dice:**
- **CaracterÃ­sticas de trÃ¡fico dominan**: Patrones de conexiÃ³n son clave
- **Variables numÃ©ricas vs categÃ³ricas**: Ambas son importantes
- **CaracterÃ­sticas de host**: Comportamiento agregado es relevante

**ConclusiÃ³n**: El modelo se basa principalmente en patrones de trÃ¡fico y caracterÃ­sticas de conexiÃ³n para detectar intrusiones.

---

### 5ï¸âƒ£ **DistribuciÃ³n de Clases** (`class_distribution.png/html`)

![Class Distribution](output/plots/class_distribution.png)

#### **DescripciÃ³n:**
Muestra la cantidad de muestras de cada clase en el dataset completo.

#### **InterpretaciÃ³n:**
- **Barra azul (Normal)**: ~67,343 muestras (53.5%)
- **Barra coral (Attack)**: ~58,630 muestras (46.5%)
- **NÃºmeros sobre barras**: Cantidad exacta de muestras

#### **QuÃ© nos dice:**
- **Dataset relativamente balanceado**: ProporciÃ³n 53/47
- **No hay desbalance severo**: No se requieren tÃ©cnicas agresivas de balanceo
- **Suficientes muestras de ambas clases**: Entrenamiento robusto

**ConclusiÃ³n**: El dataset tiene una distribuciÃ³n equilibrada, lo que facilita el entrenamiento y evita sesgos hacia una clase.

---

### 6ï¸âƒ£ **Resumen de Rendimiento** (`performance_summary.png/html`)

![Performance Summary](output/plots/performance_summary.png)

#### **DescripciÃ³n:**
ComparaciÃ³n visual de las principales mÃ©tricas de evaluaciÃ³n del modelo.

#### **InterpretaciÃ³n:**
Las 5 mÃ©tricas clave mostradas son:

1. **Accuracy (0.9987)**: ProporciÃ³n total de predicciones correctas
   - **QuÃ© mide**: Rendimiento general del modelo
   - **Valor Ã³ptimo**: 1.0 (100%)
   
2. **Precision (0.9987)**: ProporciÃ³n de predicciones positivas correctas
   - **QuÃ© mide**: Confiabilidad de las alertas de ataque
   - **Valor Ã³ptimo**: 1.0 (sin falsos positivos)
   
3. **Recall (0.9986)**: ProporciÃ³n de ataques reales detectados
   - **QuÃ© mide**: Capacidad de detectar todos los ataques
   - **Valor Ã³ptimo**: 1.0 (sin falsos negativos)
   
4. **F1-Score (0.9986)**: Media armÃ³nica de precision y recall
   - **QuÃ© mide**: Balance entre precision y recall
   - **Valor Ã³ptimo**: 1.0 (balance perfecto)
   
5. **ROC-AUC (0.9999)**: Ãrea bajo la curva ROC
   - **QuÃ© mide**: Capacidad de discriminaciÃ³n entre clases
   - **Valor Ã³ptimo**: 1.0 (separaciÃ³n perfecta)

#### **QuÃ© nos dice:**
- **Todas las mÃ©tricas > 0.998**: Rendimiento excepcional
- **MÃ©tricas equilibradas**: No hay trade-offs significativos
- **ROC-AUC casi perfecto**: Excelente capacidad de clasificaciÃ³n

**ConclusiÃ³n**: El modelo tiene un rendimiento sobresaliente en todas las mÃ©tricas, siendo apto para producciÃ³n.

---

## ğŸ¯ InterpretaciÃ³n de Resultados

### **Rendimiento del Modelo**

El Random Forest entrenado muestra un rendimiento **excepcional**:

âœ… **Fortalezas:**
- **Accuracy del 99.87%**: Clasifica correctamente casi todas las muestras
- **ROC-AUC de 0.9999**: DiscriminaciÃ³n casi perfecta entre clases
- **Muy pocos errores**: Solo 32 errores en 25,195 muestras de prueba
- **Balance perfecto**: Precision y Recall casi idÃ©nticos (no hay trade-off)
- **GeneralizaciÃ³n**: ValidaciÃ³n cruzada confirma estabilidad

âš ï¸ **Consideraciones:**
- **Posible overfitting**: Rendimiento muy alto puede indicar sobreajuste
- **Dataset sintÃ©tico**: KDD Cup 1999 es un dataset antiguo y sintÃ©tico
- **ValidaciÃ³n en producciÃ³n**: Probar con trÃ¡fico de red real
- **ActualizaciÃ³n continua**: Los patrones de ataque evolucionan

### **Aplicaciones PrÃ¡cticas**

Este modelo puede ser utilizado para:
1. **Sistemas IDS/IPS**: DetecciÃ³n en tiempo real de intrusiones
2. **AnÃ¡lisis forense**: IdentificaciÃ³n de patrones de ataque histÃ³ricos
3. **Monitoreo de red**: Alertas automÃ¡ticas de trÃ¡fico sospechoso
4. **InvestigaciÃ³n**: Baseline para comparar nuevos algoritmos

### **PrÃ³ximos Pasos Recomendados**

1. **ValidaciÃ³n con datos reales**: Probar con trÃ¡fico de red actual
2. **AnÃ¡lisis de errores**: Estudiar los 32 casos mal clasificados
3. **OptimizaciÃ³n**: Reducir el tamaÃ±o del modelo sin perder rendimiento
4. **Deployment**: Integrar en un sistema de monitoreo real
5. **ActualizaciÃ³n**: Reentrenar con nuevos tipos de ataques

---

## ğŸ“ Estructura de Archivos

```
Prueba-dataset/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_and_chunk.py          # Descarga y preprocesa datos
â”‚   â”œâ”€â”€ train_random_forest.py         # Entrena el modelo
â”‚   â”œâ”€â”€ generate_visualizations.py     # Genera grÃ¡ficos
â”‚   â””â”€â”€ KDD_TRAIN_FULL.csv            # Dataset procesado
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ rf_kdd_model.joblib           # Modelo entrenado
â”‚   â”œâ”€â”€ rf_kdd_metrics.txt            # MÃ©tricas de evaluaciÃ³n
â”‚   â””â”€â”€ plots/                         # Visualizaciones
â”‚       â”œâ”€â”€ confusion_matrix.png/html
â”‚       â”œâ”€â”€ roc_curve.png/html
â”‚       â”œâ”€â”€ precision_recall.png/html
â”‚       â”œâ”€â”€ feature_importance.png/html
â”‚       â”œâ”€â”€ class_distribution.png/html
â”‚       â””â”€â”€ performance_summary.png/html
â””â”€â”€ README_TRAINING.md                 # Esta documentaciÃ³n
```

---

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### **1. Preparar los datos**
```bash
python scripts/download_and_chunk.py
```

### **2. Entrenar el modelo**
```bash
python scripts/train_random_forest.py
```

### **3. Generar visualizaciones**
```bash
python scripts/generate_visualizations.py
```

---

## ğŸ“š Referencias

- **Dataset**: KDD Cup 1999 - Network Intrusion Detection
- **Algoritmo**: Random Forest (Breiman, 2001)
- **MÃ©tricas**: Scikit-learn Documentation
- **Visualizaciones**: Plotly Python Library

---

**Autor**: Sistema de DetecciÃ³n de Intrusiones con Machine Learning  
**Fecha**: 2025  
**VersiÃ³n**: 1.0
