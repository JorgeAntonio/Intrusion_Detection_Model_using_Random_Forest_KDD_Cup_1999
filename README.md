# ğŸ›¡ï¸ Sistema de DetecciÃ³n de Intrusiones con Machine Learning

Sistema de Machine Learning para detecciÃ³n de intrusiones de red utilizando **mÃºltiples algoritmos** sobre el dataset **KDD Cup 1999**. El sistema clasifica el trÃ¡fico de red en dos categorÃ­as: **Normal** y **Attack** (intrusiÃ³n).

## ğŸ¯ CaracterÃ­sticas del Proyecto

- **4 Modelos de ML**: Random Forest, AdaBoost, Gradient Boosting, Voting Classifier
- **Accuracy**: >99.8% en todos los modelos
- **ROC-AUC**: >0.999 en todos los modelos
- **Dataset**: KDD Cup 1999 (~126,000 muestras)
- **ComparaciÃ³n completa**: MÃ©tricas, visualizaciones y anÃ¡lisis comparativo
- **Visualizaciones**: 15+ grÃ¡ficos interactivos (HTML) y estÃ¡ticos (PNG)

## ğŸ“ Estructura del Proyecto

```
Prueba-dataset/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_and_chunk.py          # Descarga y preprocesa el dataset
â”‚   â”œâ”€â”€ train_random_forest.py         # Entrena Random Forest
â”‚   â”œâ”€â”€ train_adaboost.py              # Entrena AdaBoost
â”‚   â”œâ”€â”€ train_gradient_boosting.py     # Entrena Gradient Boosting
â”‚   â”œâ”€â”€ train_voting_classifier.py     # Entrena Voting Classifier
â”‚   â”œâ”€â”€ train_all_models.py            # Entrena TODOS los modelos
â”‚   â”œâ”€â”€ compare_models.py              # Compara todos los modelos
â”‚   â”œâ”€â”€ visualize_comparison.py        # Visualizaciones comparativas
â”‚   â”œâ”€â”€ generate_visualizations.py     # Visualizaciones individuales
â”‚   â””â”€â”€ KDD_TRAIN_FULL.csv            # Dataset procesado (generado)
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ *_kdd_model.joblib            # Modelos entrenados (4 archivos)
â”‚   â”œâ”€â”€ *_kdd_metrics.txt             # MÃ©tricas individuales (4 archivos)
â”‚   â”œâ”€â”€ models_comparison.txt/csv     # ComparaciÃ³n de modelos
â”‚   â”œâ”€â”€ plots/                         # Visualizaciones individuales
â”‚   â””â”€â”€ comparison_plots/              # Visualizaciones comparativas
â”œâ”€â”€ requirements.txt                   # Dependencias del proyecto
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ README_TRAINING.md                 # DocumentaciÃ³n tÃ©cnica detallada
â””â”€â”€ README_COMPARISON.md               # GuÃ­a de comparaciÃ³n de modelos
```

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### **Paso 1: Instalar Dependencias**

```powershell
# Crear entorno virtual (recomendado)
python -m venv .venv
.venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

### **Paso 2: Descargar y Procesar el Dataset**

```powershell
python .\scripts\download_and_chunk.py
```

Este script:
- Descarga el dataset KDD Cup 1999 (DDTrain.txt)
- Aplica one-hot encoding a variables categÃ³ricas
- Crea la variable objetivo binaria (0=Normal, 1=Attack)
- Genera `scripts/KDD_TRAIN_FULL.csv` con ~120 caracterÃ­sticas

### **Paso 3: Entrenar Modelos**

#### **OpciÃ³n A: Entrenar TODOS los modelos (Recomendado)**

```powershell
python .\scripts\train_all_models.py
```

Este script ejecuta automÃ¡ticamente:
1. Entrenamiento de Random Forest
2. Entrenamiento de AdaBoost
3. Entrenamiento de Gradient Boosting
4. Entrenamiento de Voting Classifier
5. ComparaciÃ³n de todos los modelos
6. GeneraciÃ³n de visualizaciones comparativas

**Tiempo estimado**: 30-60 minutos

#### **OpciÃ³n B: Entrenar modelos individualmente**

```powershell
# Random Forest (5-10 min)
python .\scripts\train_random_forest.py

# AdaBoost (10-15 min)
python .\scripts\train_adaboost.py

# Gradient Boosting (15-20 min)
python .\scripts\train_gradient_boosting.py

# Voting Classifier (20-30 min)
python .\scripts\train_voting_classifier.py
```

### **Paso 4: Comparar Modelos**

```powershell
# Generar comparaciÃ³n detallada
python .\scripts\compare_models.py

# Generar visualizaciones comparativas
python .\scripts\visualize_comparison.py
```

Esto genera:
- **Tabla comparativa** con todas las mÃ©tricas
- **7 visualizaciones** comparando los modelos
- **Ranking** de modelos por rendimiento
- **AnÃ¡lisis de errores** (FP, FN, tasas)

### **Paso 5: Visualizaciones Individuales (Opcional)**

```powershell
python .\scripts\generate_visualizations.py
```

Genera 6 visualizaciones para Random Forest:
1. **Matriz de ConfusiÃ³n**: Errores de clasificaciÃ³n
2. **Curva ROC**: Capacidad de discriminaciÃ³n
3. **Curva Precision-Recall**: Balance entre precisiÃ³n y recall
4. **Importancia de CaracterÃ­sticas**: Top 15 features
5. **DistribuciÃ³n de Clases**: Balance del dataset
6. **Resumen de Rendimiento**: MÃ©tricas principales

## ğŸ“Š Resultados del Modelo

### **MÃ©tricas de Rendimiento**

| MÃ©trica | Valor |
|---------|-------|
| Accuracy | 99.87% |
| Precision | 99.87% |
| Recall | 99.86% |
| F1-Score | 99.86% |
| ROC-AUC | 0.9999 |

### **Matriz de ConfusiÃ³n**

```
                Predicted Normal    Predicted Attack
Actual Normal        13,454              15
Actual Attack           17            11,709
```

- **Falsos Positivos**: 15 (0.1%)
- **Falsos Negativos**: 17 (0.1%)
- **Total de errores**: 32 de 25,195 muestras

### **HiperparÃ¡metros Ã“ptimos**

- `n_estimators`: 121
- `max_depth`: 16
- `max_features`: log2
- `min_samples_split`: 4
- `min_samples_leaf`: 1

## ğŸ“š DocumentaciÃ³n TÃ©cnica

### ğŸ“– **[README_TRAINING.md](README_TRAINING.md)** - DocumentaciÃ³n de Entrenamiento
- DescripciÃ³n completa del proceso de entrenamiento
- ExplicaciÃ³n de las 120+ caracterÃ­sticas del dataset
- InterpretaciÃ³n detallada de cada grÃ¡fico
- AnÃ¡lisis de resultados y recomendaciones

### ğŸ”¬ **[README_COMPARISON.md](README_COMPARISON.md)** - GuÃ­a de ComparaciÃ³n de Modelos
- DescripciÃ³n de los 4 modelos implementados
- Ventajas y desventajas de cada algoritmo
- MÃ©tricas de comparaciÃ³n y criterios de selecciÃ³n
- InterpretaciÃ³n de visualizaciones comparativas
- Recomendaciones para producciÃ³n

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.12**
- **scikit-learn**: Random Forest, mÃ©tricas, validaciÃ³n cruzada
- **pandas**: ManipulaciÃ³n de datos
- **numpy**: Operaciones numÃ©ricas
- **plotly**: Visualizaciones interactivas
- **joblib**: SerializaciÃ³n del modelo

## ğŸ“¦ Dependencias

```
pandas
numpy
requests
scikit-learn
plotly
kaleido
joblib
```

## âš ï¸ Notas Importantes

- **Dataset**: Si la descarga automÃ¡tica falla, coloca el archivo `KDDTrain.txt` en `C:\Users\TU_USUARIO\Desktop\IA DATASET\Datasets\` o actualiza la ruta en `download_and_chunk.py`
- **Memoria**: El entrenamiento requiere ~4-6 GB de RAM
- **Tiempo**: 
  - Un solo modelo: 5-20 minutos
  - Todos los modelos: 30-60 minutos
- **Modelos guardados**: Cada archivo `.joblib` pesa entre 2-10 MB

## ğŸ¯ Aplicaciones

Este modelo puede ser utilizado para:
- Sistemas de DetecciÃ³n de Intrusiones (IDS)
- Monitoreo de red en tiempo real
- AnÃ¡lisis forense de trÃ¡fico de red
- InvestigaciÃ³n en ciberseguridad

## ğŸ“ˆ PrÃ³ximos Pasos

- [ ] Validar con trÃ¡fico de red real
- [ ] Implementar detecciÃ³n en tiempo real
- [ ] Agregar mÃ¡s algoritmos (XGBoost, LightGBM, Neural Networks)
- [ ] Optimizar hiperparÃ¡metros con Optuna o Hyperopt
- [ ] Crear API REST para predicciones
- [ ] Implementar explicabilidad con SHAP o LIME
- [ ] Desplegar en producciÃ³n con Docker

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para fines educativos y de investigaciÃ³n.

---

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!**
